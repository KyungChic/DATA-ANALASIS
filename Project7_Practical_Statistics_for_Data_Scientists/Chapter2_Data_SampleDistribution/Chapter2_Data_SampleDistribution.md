# 2장 데이터와 표본분포

### 2.1 임의 표본 추출과 표본편향

- 비임의(nonrandom) : 랜덤표본이라 해도 무작위 추출의 대상에 따라 편향이 발생할 수 있는데, 비임의 표본의 경우 어떠한 모집단도 대표할 수 없게 된다.



### 2.1.1 편향(bias)

- 통계적 편향 :  표본추출 과정에서 발생하는 계통적인(systemic) 오차를 의미. 단순히 어느 값(과녁의 중앙)과 불일치 한다는 것이 아니라 일관적인, 예를 들면 과녁의 1사분면에만 총알이 밀집되어 있다면 이는 편향이 있는 것으로 볼 수 있다.



### 2.1.2 임의선택

- **임의표본추출**은 표본의 대표성을 담보하는 핵심적인 방법이다
- **층화표본추출**에서는 모집단을 여러 층으로 나누고, 층( strata)에서 무작위로 샘플을 추출한다.



### 2.1.3 크기와 품질 : 크기는 언제 중요해질까?

- 임의표본추출에 시간과 노력을 기울일수록 데이터 탐색 및 품질을 향상시킬 수 있다.
- 대량의 데이터는 데이터가 크고 동시에 희소할 때 필요하다.(예: 구글의 검색 문제 - 15만 개의 영단어 + 연간 1조 개 이상의 검색어 --> 빅데이터가 있어야 효과적인 검색 품질 제공이 가능하다.)



### 2.2 선택편향

- **선택편향** : 데이터를 의식/무의식적으로 선택에 따라 고르는 것. --> 단편적인 결론에 이르게 됨.

  

- 잘 설계된 실험에 기반한 데이터 분석 결과는 신뢰성이 높지만, 일반적으로는 먼저 데이터를 수집한 후 그 안의 패턴을 탐색하게 되는데, 이를 **데이터스누핑**이라고 함. 

- 데이터스누핑에 의한 패턴 도출은  참된 패턴인지 알기가 어렵다.



- 선택편향의 한 사례로 **방대한 검색 효과**가 있다. 큰 데이터 집합을 가지고 반복적으로 다른 모델을 만들고, 다른 질문을 하다 보면 언젠가는 흥미로운 사실을 발견하게 되는데, 이 결과가 과연 의미가 있는 결과물일지는 신뢰하기 어렵다.



### 2.1.1 평균으로의 회귀

- **평균으로의 회귀(regression to the mean)**란 어떤 변수를 연속적으로 측정했을 때 나타난다. 예외적인 경우가 관측된 후 연속적으로 관찰하면 그 다음에는 중간 정도의 경우가 관찰되는경향이 있다.  --->  따라서 예외적인 경우를 너무 특별히 생각하고 의미를 부여하면 선택 편향으로 이어진다.



### 2.3 통계학에서의 표본분포

- **표본분포(sampling distribution)** : 여러 표본들 혹은 재표본들로부터 얻은 표본통계량의 '도수분포'
- 주요 관심사는 표본의 편동성이다. 많은 양의 데이터를 갖고 있다면, 통계의 분포를 파악하여 변동성을 볼 수 있다.(히스토그램)
- 히스토그램을 그려보면 표본의 수가 늘어날수록 좁은 종 모양이 된다. 이러한 현상을 **중심극한정리** 라고 한다.



#### R코딩 정리

- **rep(x, n)** : x를 n만큼 반복한다.  /  x가 벡터라면? : 그에 대응하는 n이 필요하다

  - ex1) rep (c(1,2), c(3,4))  실행 시 1,1,1,2,2,2,2 (1-3번 2-4번 반복)
  - ex2) rep(1:1000, rep(5,1000)) 실행 시 1~1000의 숫자를 모두 5번씩 반복

  

- **tapply(data, group, FUN=NULL)** :data를 group 기준으로, FUN 함수를 계산하여 출력

  - ex) a그룹(1,2,3,4,5) / b(6,7,8,9,10) 데이터 셋 data에 대해

    - | group | value |
      | ----- | ----- |
      | a     | 1     |
      | a     | 2     |
      | a     | 3     |
      | a     | 4     |
      | a     | 5     |
      | b     | 6     |
      | b     | 7     |
      | b     | 8     |
      | b     | 9     |
      | b     | 10    |

    

  - 다음의 함수를 적용해보면

    ```R
    tapply(data, data$group, FUN=mean)
    ```

    - 아래와 같은 값이 출력된다.

      | a    | b    |
      | ---- | ---- |
      | 3    | 8    |

  - 

  - 미리 그룹이 지정되어 있지 않아도 함수 실행 과정에서 그룹을 나눌 수도 있다.

    ```R
    tapply(data, rep(c(a,b), c(5,5)), FUN=mean)
    ```

    - 출력 값을 위와 동일하다.




#### python 코딩 정리

- **for문의 _  (underscore())**

  - for 문에서 _를 변수로 지정하는 경우 크게 의미없다는 뜻으로 보며 된다

  ```python
  for _ in range(1000)
  ```

  

- pandas의 concat 함수

  - concatenate의 약자로서, 데이터를 연결하는 기능을 함
  - 기본적인 형식은 다음과 같음

  ```python
  pd.concat([series1, series2, ...])
  
  pd.concat([df1, df2, ...])
  ```

  - series를 연결하는 경우 index가 있다면 index별로, 없다면 순서별로 연결.
  - df를 연결하는 경우 index / column 별로 연결한다.(index가 없다면 순서대로)

  

- 데이터를 불러와서 DF를 만드는 경우, DF상 모든 값이 Scalar 값일 경우 오류가 발생하게 되는데, 이때에는 데이터를 불러올 당시 다음의 옵션을 지정함으로써 해결할 수 있다.

  ```python
  loans_income = pd.read_csv("loans_income.csv", squeeze=True)
  ```

  - squeeze 옵션은 데이터를 불러올 때 column이 하나만 있으면 리스트 형태로 값을 반환하는 옵션인데, 구체적인 건 잘 모르겠다.

  

### 2.3.2 표준오차

- 통계에 대한 표본분포의 변동성을 한마디로 말해주는 단일 측정지표로, 다음과 같이 계산된다.	
  $$
  표준오차 = SE = \dfrac{s}{\sqrt{n}}
  $$



- 실질적으로 표준오차를 낮추기 위해서는 새로운 샘플을 수집하여야 하지만, 이는 현실적으로 불가능할 때가 많고, 통계적으로도 낭비가 심하다.
- 다행히, **부트스트랩** 재표본을 사용할 수 있는데, 이는 <u>사실상 모든 통계에 사용할 수 있으며, 중심극한 정리 및 분포 가정에 의존하지 않는 장점이 있다.</u>



### 2.4 부트스트랩

- 표본분포를 추정하는 쉽고 효과적인 방법으로서, 현재 표본에서 복원추출을 통해 통계량과 모델을 계산하는 방법
- 정규분포에 대한 가정이 존재하지 않는다.
- 추출 횟수 R은 하이퍼 파라미터로서 사용자가 결정. 많을수록 데이터 추정이 더 정확해진다.

------------------------------

#### R 코드

- 부트스트랩 코드를 실행하면 다음의 결과가 얻어진다.
  - original : 중간값의 원래 추정치는 62,000달러이다.
  - bias : 부트스트랩 분포는 추정치에서 약 -74.55 달러의 편향이 있다.
  - std. error : 부트스트랩 분포는 추정치에서 약 217.81 달러의 표준오차가 있다.

```R
Bootstrap Statistics :
    original   bias    std. error
t1*    62000 -74.5535    217.8089
```



#### python 코드

- 파이썬은 애초에 정형화된 부트스트랩 코드를 제공하지 않음 : scikit-learn의 resample 메서드를 이용한다

--------------------------------



- 그 밖에 부트스트랩은 다변량 데이터에도 적용될 수 있다. 이때, 각 행은 여러 변수들의 값을 포함하는 하나의 샘플을 의미하게 된다.
- 분류 및 회귀 트리(의사결정트리)를 사용할 때에도 여러 부트스트랩 샘플을 통해 트리를 여러 개 만든 다음 각 트리의 예측값의 평균을 사용하는 방식이 더 효과적인데, 이를 **배깅** 이라고 부른다.



- 부트스트랩은 표본크기가 작은 것을 보완하는 수단은 아니며, 빈 데이터를 채우는 용도도 아니다. 다만, <u>모집단에서 추가적으로 표본을 뽑는다고 할 때, 그 표본이 원래 표본과 얼마나 비슷할지를 알려줄 뿐이다.</u>



### 2.5 신뢰구간

- 분석가나 관리자는 불확실성을 알면서도 점추정치가 주어진 경우 과도한 믿음을 두는 경우가 있는데, 이를 방지하고자 추정치를 구간으로 제시한다.
- 과거에 계산이 어렵던 시절에는 t-분포에 의한 신뢰구간을 사용했다.
- 하지만 이제는 부트스트랩을 통해 재표본추출을 하고, 해당하는 표본의 분포를 바탕으로 신뢰구간 및 추정치를 보여주는 방법이 사용되고 있다.



### 2.6 정규분포(normal distribution)

- 대부분의 데이터가 정규분포이기 때문에 정상(normal)의 의미로 사용되는 것은 아니다. 실제로 대부분의 원시 데이터는 전반적으로 정규분포를 따르지 않는다.
- 따라서 정규분포는 표본분포에서 통계량이 정규분포를 따를 때 유용한 것이며, 일반적으로는 경험적 확률분포나 부트스트랩 분포를 구할 수 없는 경우 최후의 수단으로 사용된다.



### 2.6.1 표준정규분포와 QQ그림

- **표준정규분포**는 정규분포를 표준화 한 분포값으로서 x축의 단위가 평균의 표준편차로 표현되는 정규분포를 말한다. 이 때 정규화된 변환 값을 z 점수(z-score)라고 하며, 표준정규분포를 z 분포(z-distribution)라고 하기도 한다.
- **QQ그림**은 표본이 특정 분포에 얼마나 가까운지를 시각적으로 판별할 때 사용된다.(지금은 정규분포를 판별하기위해 사용)
  - z 점수를 오름차순으로 정렬하고, 각 값의 z 점수를 y축 위에 표시한다. x 축은 정규분포에서의 해당 분위수를 나타낸다.
  - 데이터가 표준화되었기 때문에 단위는 평균으로부터 떨어진 데이터의 표준편차 수에 해당하며 점들이 <u>대각선 위에 놓이게 되면 정규분포에 가깝다</u>고 할 수 있다.



### 2.7 긴 꼬리 분포

- 데이터는 일반적으로 정규분포를 따르지 않는다. 때로는 분포가 소득 데이터와 같이 비스듬하게 기울어져 있거나 이항 데이터와 같이 이산적일 수 있다.
- 대칭 및 비대칭 분포 모두 **긴 꼬리(long tail)**를 가질 수 있으며, 분포의 꼬리는 양 극한값에 해당한다. 실무에서는 긴 꼬리 분석을 중요하게 여기는데, 나심탈레브의 블랙스완이론은 이러한 극한 값이 정규분포로 예측되는 확률보다 훨씬 더 자주 일어날 수 있음을 보인다.
- 긴 꼬리 분포의 QQ그림을 그려보면 가운데는 정규분포에 가깝지만 양 끝 값이 대각선에서 벗어남을 알 수 있다.



### 2.8 스튜던트의 t 분포

- t 분포는 정규분포와 생김새가 비슷하지만 꼬리 부분이 약간 더 두껍고 길다.
- t 분포는 표본통계량의 분포를 설명하는 데에 광범위하게 사용된다
- 표본이 클수록 t 분포는 정규분포의 모습을 닮게 된다. 
- 표본통계량의 상태를 묘사할 때 t 분포의 정확도는 표본 통계량의 분포가 정규분포를 따른다는 조건이 필요하다. 이는 모집단의 분포가 정규분포가 아니더라도 중심극한 정리에 따란 표본통계량은 정규분포를 따르게 된다는 원리에 의거하여 t분포는 널리 사용되고 있다.



### 2.9 이항분포

- 이항분포를 이해할 때 핵심은 **시행**이라는 아이디어인데, 각 시행은 정해진 확률로 두 가지 결과를 갖는다.
- 0/1, 예/아니오, 구매/구매하지않음 등 이진 결과를 갖게되며, 확률은 꼭 50 대 50일 필요는 없고, 합계가 1이 되면 된다.
- 이항분포의 주요 변수들
  - 성공 확률 p
  - 시행 횟수 n
  - 성공한 횟수 x
- 이항분포는 성공한 주어진 n과 p에 따른 성공 횟수 x의 분포를 나타낸다.
- 이항분포의 평균은 n x p 이며, 성공 확률이 p 인 경우 n 번의 시행에서 예상되는 성공 횟수로 생각할 수도 있다.
- 이항분포의 분산은 n x p x (1-p) 이며, 시행횟수가 충분할 때(그리고 특히 p가 0.5에 가까울 때) 이항분포는 정규분포와 구분이 어렵다. 표본이 커질수록 이항분포는 계산이 어려워지기 때문에 평균과 분산으로 정규화한 정규분포를 통해 근사값을 계산하게 된다.



### 2.10 카이제곱분포

- 카이제곱 통계량은 검정 결과가 <u>독립성에 대한 귀무가설에서 벗어난 정도</u>를 측정하는 통계량이다.
- 관측값과 기댓값의 차이를 기댓값의 제곱근으로 나눈 값을 다시 제곱하고 모든 범주에 대해 합산한 값이다.
- 더 일반적으로 카이제곱 통계량은 <u>관측 데이터가 특정 분포에 적합한 정도</u>를 나타낸다.(정합도 검정) : 여러 처리('A/B/C ... 검정')의 효과가 서로 다른지 여부를 결정하는 데 유용하다.
- 카이제곱분포는 귀무 모델에서 반복적으로 재표본추출한 통계량 분포로서 카이제곱 값이 낮다는 것은 기대 분포를 거의 따르고 있음을 나타낸다.

> - 카이제곱검정은 분할표에서 빈도를 비교하는 것으로 검정을 수행한다.
> - 목적에 따라 세 가지로 분류해볼 수 있다.
>   - 적합도검정(Goodness of fit)
>     - 범주형인 하나의 변수에 대해 기대하는 어떤 분포를 따르는지 여부를 검정.
>       - 귀무가설 : 변수 X의 관측 분포와 기대(이론)분포가 동일하다.
>       - 대립가설 : 변수 X의 관측 분포와 기대(이론)분포가 다르다.
>   - 독립성검정(Test of Independence)
>     - 범주형인 두 변수가 서로 연관되어 있는지 여부를 검정.
>       - 귀무가설 : 변수 X와 Y는 서로 독립이다.
>       - 대립가설 : 변수 X와 Y는 서로 독립이 아니다.
>   - 동질성검정(Test of Homogeneity)
>     - 두 변수의 연관관계가 아닌, 두 변수의 확률분포가 동일한지 여부를 검정
>       - 귀무가설 : 각 그룹의 확률분포가 동일하다.
>       - 대립가설 : 각 그룹의 확률분포가 동일하지 않다.



### 2.11 F 분포

- 여러 그룹에 걸쳐 서로 다른 처리를 테스트 하는 과정에서 그룹 평균간의 차이가 정규 무작위 변동에서 예상할 수 있는 것보다 얼마나 큰지를 설펴보는 통계량.
- 카이제곱 분포의 A/B/C검정과 유사하지만 연속된 관측값을 처리한다는 차이가 있다.
- **F 통계량**은 각 그룹 내 변동성(잔차 변동성이라고 하기도 함)에 대한 그룹 평균 간 변동성의 비율을 의미한다.
- 이러한 비교를 분산분석(ANOVA : ANalysis Of VAriance) 이라고 한다.
- F 통계량의 분포는 모든 그룹의 평균이 동일한 경우(귀무 모델) 무작위 순열 데이터에 의해 생성되는 모든 값의 빈도 분포로서 자유도에 따라 다양한 F 분포가 있다.
- F 통계량은 회귀모형에 의해 설명된 변동성을 데이터 전체의 변동과 비교하기 위해 선형회귀에도 사용된다.



### 2.12 푸아송 분포와 그 외 관련 분포들



#### 2.12.1 푸아송분포

- 주어진 어떤 비율에 따라 발생하는 사건들
  - 시간에 따른 사건 : 웹사이트 방문객 수, 톨게이트에 들어오는 자동차 수
  - 공간에 따른 사건 : 1제곱미터당 건물의 결함, 코드 100줄 당 오타
- 집계 데이터에 대해 시간 단위 / 공간 단위로 표본들을 수집할 때 그 사건들의 분포를 설명하는 분포가 푸아송분포이다.
  - ex) 5초 동안 서버에 도착한 인터넷 프래픽을 95% 확률로 완벽하게 처리하는 데 필요한 용량은?
- 푸아송분포의 핵심 파라미터는 λ(람다)이다. 
  - 람다는 어떤 일정 시간 / 공간의 구간 안에서 발생한 평균 사건 수를 의미한다.
  - 푸아송 분포의 분산도 λ(람다)이다.



#### 2.12.2 지수분포

- 푸아송분포의 것과 동일한 λ(람다) 변수를 사용하여 사건과 사건 간의 시간 분포를 모델링함.
  - ex) 웹사이트 방문이 일어난 시간, 톨게이트 자동차가 도착하는 시간, 고장이 발생하는 시간, 개별 고객 상담에 소요되는 시간 등
- 지수분포의 난수를 생성하기 위한 인수로는 n(난수 발생 개수)과 비율(시간 주기당 사건 수)를 사용한다.



